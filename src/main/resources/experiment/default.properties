# Experiment properties
Experiment.SimulatorType = sequential
Experiment.RandomSeed = -1
Experiment.TotalRuns = 1
Experiment.TotalUpdates = 10000000
Experiment.ObservationCount = 100
Experiment.Simulation = org.madesimple.small.experiment.simulation.RollOut
#Experiment.Simulation = org.madesimple.small.experiment.simulation.Sampling
Experiment.Environment = mountain-car
Experiment.Agent = org.madesimple.small.agent.learning.DiscreteLearningAgent
Experiment.Visualise = true

# Visualiser: Mountain Car
Visualiser.Grid.Render = false


# Agent: DiscreteLearningAgent
Agent.LearningAlgorithm = org.madesimple.small.agent.learning.algorithm.Sarsa


# LearningAlgorithm: Q
LearningAlgorithm.Q.Alpha = 0.4
LearningAlgorithm.Q.Gamma = 0.999
LearningAlgorithm.Q.Strategy = org.madesimple.small.agent.strategy.EpsilonGreedy
LearningAlgorithm.Q.InitialValue = 0.0d
# LearningAlgorithm: RMax
LearningAlgorithm.RMax.Gamma = 0.99
LearningAlgorithm.RMax.M = 5
LearningAlgorithm.RMax.Epsilon = 1
LearningAlgorithm.RMax.UpperBound = 10
LearningAlgorithm.RMax.InitialValue = 0.0d
# LearningAlgorithm: SARSA
LearningAlgorithm.SARSA.Alpha = 0.4
LearningAlgorithm.SARSA.Gamma = 0.999
LearningAlgorithm.SARSA.Strategy = org.madesimple.small.agent.strategy.EpsilonGreedy
LearningAlgorithm.SARSA.InitialValue = 0.0d
# LearningAlgorithm: TileCode
LearningAlgorithm.TileCode.Alpha = 0.4
LearningAlgorithm.TileCode.Gamma = 0.999
LearningAlgorithm.TileCode.Storage = org.madesimple.small.agent.learning.storage.tilecoding.Whiteson
LearningAlgorithm.TileCode.Strategy = org.madesimple.small.agent.strategy.EpsilonGreedy

# Storage: TileCoding
TileCoding.NumTilings = 4
TileCoding.Sutton.NumTiles = 50
TileCoding.Whiteson.TilesPerFeature = 50,50


# Strategy: Boltzmann
Strategy.Boltzmann.Tau = 0.4
Strategy.Boltzmann.ShouldDecay = true
Strategy.Boltzmann.Type = linear
Strategy.Boltzmann.Over = 300
Strategy.Boltzmann.Minimum = 0
Strategy.Boltzmann.Start = 0
# Strategy: EpsilonFirst
Strategy.EpsilonFirst.Epsilon = 0.1
Strategy.EpsilonFirst.N = 500
# Strategy: EpsilonGreedy
Strategy.EpsilonGreedy.Epsilon = 0.4
Strategy.EpsilonGreedy.Type = linear
Strategy.EpsilonGreedy.Over = 300
Strategy.EpsilonGreedy.Minimum = 0
Strategy.EpsilonGreedy.Start = 0
Strategy.EpsilonGreedy.L = 500
Strategy.EpsilonGreedy.k = 2


# Environment: Acrobot
Environment.Acrobot.RewardPerStep = -1.0d
Environment.Acrobot.RewardAtGoal = 0.0d
Environment.Acrobot.RandomStarts = true
Environment.Acrobot.TransitionNoise = 0.0d
Environment.Acrobot.MaxTurns = 4000
# Environment: GridWorld2d
Environment.GridWorld2d.LayoutFilePath = src/main/resources/environment/gridworld2d/layoutMazeSingleAgent.map
Environment.GridWorld2d.AvailableActions = cardinal
Environment.GridWorld2d.MaxTurns = 100
Environment.GridWorld2d.NumAgents = 1
#Environment: MountainCar
Environment.MountainCar.RewardPerStep = -1.0d
Environment.MountainCar.RewardAtGoal = 0.0d
Environment.MountainCar.RandomStarts = false
Environment.MountainCar.TransitionNoise = 0.0d
Environment.MountainCar.MaxTurns = 4000
